---
title: Week 7
---


{% assign filedir = site.baseurl | append: page.subpath %} 
{% assign notes_path = filedir | append: "notes/" %} 
{% assign project = filedir | append: "project_proposal.pdf" %}

<!--  
Instructions:

INDENTATION COUNTS

Each day should be formatted exactly as follows

Date
: Lessons Covered
  : Reading List
    : In Class Presentations
: **Assignment/Announcement**{: .label}


To add a hyperlink for readings, do it as follows
  : [Example Paper](http://linktopaper.edu)

To make the hyperlink open in a new tab by default
  : [Example Paper](http://linktopaper.edu){:target=_"blank"}

The announcement can be made red for due dates as follows
: **Assignment Due**{: .label .label-red }

10/7 RLHF/PPO/DPO
10/9 Ethics
-->

Oct 7
: Reinforcement Learning with Human Feedback: Proximal Policy Optimization (PPO) and Direct Preference Optimization (DPO)
  : - 

Oct 9
: [ethics]({{site.baseurl}}assets/files/ethics.pdf) (Guest Lecture by Katy Felkner)
  : [The Social Impact of Natural Language Processing](https://aclanthology.org/P16-2096.pdf), [Energy and Policy Considerations for Deep Learning in NLP](https://aclanthology.org/P19-1355/), [Model Cards for Model Reporting](https://arxiv.org/abs/1810.03993)
    : Daniel P - [Extracted BERT Model Leaks More Information than you Think!](https://aclanthology.org/2022.emnlp-main.99/)
    : Questions by: Tianyi 

<!-- : [constituencies, cky]({{site.baseurl}}assets/files/constit.pdf)
  : E 10.1--10.4, JM 17 (the rest)
    : Ian - [Finding Skill Neurons in Pre-trained Transformer-based Language Models](https://aclanthology.org/2022.emnlp-main.765/)
    : Questions by: Deuksin
    : Darshan - [On the Transformation of Latent Space in Fine-Tuned NLP Models](https://aclanthology.org/2022.emnlp-main.97)
    : Questions by: Shauryasikt
 -->


<!-- Oct 6 -->
<!-- : Drop deadline (no refund, without W) -->

